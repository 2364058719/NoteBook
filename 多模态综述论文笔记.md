[TOC]



# Multimodal Machine Learning: A Survey and Taxonomy 2019

问题：

- 研究背景是什么（introduction）
- 前人做了哪些方面的工作，获得了怎样的成果
- 存在哪些问题有待解决（总结和展望）

词汇：

> multimodal 多模态	taxonomy分类	fusion融合	broader更广泛的	identify确定	sensory感官	modalities模态	but not exclusively但不限于	heterogeneity异质的	complementarity互补性	redundancy冗余	symbolic符号	subjective主观的	ambiguities模糊性	relevant重要的	emerging新兴的	syllable音	perceived感知	given the prominence of鉴于	 robustness鲁棒性	interpersonal人际的	representative代表性	inverse逆转	have been superseded by被取代/被超越	textual文本	projection投影	successive连续	metric 度量	heuristics启发式	



- 多模态研究方向：
  - representation：
  
    - 利用多模态数据的互补与冗余来学习和总结
    - data异质性
  
    1. 语言是符号化的，然而图片和音频模态通常被表示为信号
  
  - translation
  
    - data异质性、两个模态的relationship是开放和主观的
  
  - alignment
  
    - 确定来自多个模态的元素、子元素之间的direct relations
    - 确定不同模态之间的相似性
    - 可能存在long-range的依赖和模糊性
  
  - fusion
  
    - 运用多个模态的信息去perform a prediction
      1. 视听语音识别中，唇部动作的视觉描述和语言信号融合去预测说的词
    - 不同模态的信息具有不同预测功能和噪声拓扑结构，并且可能丢失至少一种模态的数据
  
  - co-learning
  
    - 不同模态之间的知识转移
    - co-training, conceptual grounding, and zero shot learning
  
- 文中主要关注模态：
  - 自然语言（written and spoken）
  - visual signals（images and videos）
  - vocal signals（sounds and para-verbal）



- 早期的视听识别（AVSR）基于各种隐式马尔可夫模型（HMM）

- 多媒体的内容索引和检测

  - 早期是基于keyword
  - 多媒体内容分析
    - 自动shot-boundary检测
    - video摘要

-  understanding human multimodal behaviors during social interactions.

  - 情感识别
    - 多模态效果减弱，当识别 naturally-occurring emotions.时

- media description：language & vision

  - image captioning

  - media generation from text

    challenge：evaluation（ how to evaluate the quality of the predicted descrip-tions and media.）

    -  visual question-answering (VQA)

### representation

how to combine the data from heterogeneous sources; 

how to deal with different levels of noise; 

how to handle missing data

- goods representation properties：

  smoothness, temporal and spatial coherence, sparsity, and natural clus-tering amongst others

- additional desirable properties：

   similarity in the representation space should reflect the similarity of the corresponding concepts, the representation should be easy to obtain even in the absence of some modalities, and finally, it should be possible to fill-in missing modalities given the observed ones.

- The development of unimodal representations has been extensively studied

-  a shift from hand-designed for specific applica-tions to data-driven

- natual language 处理使用word embeddings方式学习（利用word context）

-  joint and coordinated
  - joint
    - neural networks, 
      1. 可end-to-end训练
      2. 预训练：stacked denoising autoencoders to rep-resent each modality individually and then fused them into a multimodal representation using another autoencoder layer
      3. 优势：
         - 预训练和微调
      4. 劣势：
         - 不能处理数据丢失（有方法缓解 ！！！）
    -  graphical models：通过使用潜在的随机变量构建表征
      1. 在单模态数据经过非线性变换后的后期阶段整合数据对模型有利
      2. 优势：
         - 生成性：easy way to 处理数据缺失
      3. 劣势：
         - 难以训练，计算资源消耗大，需要运用多种训练方法
    - Sequential Representation./recurrent neural net-works
      1. RNNs/LSTM：表示不定长数据
      2. 视听识别、情感识别、多视角数据（人类行为分析）
  - Coordinated
    - similarity
      1. web scale annotation by image embedding model,
      2. DeViSE—a deep visual-semantic embed-ding （相似内积、排序损失函数）
      3. using an LSTM model and a pairwise ranking loss to coordinate the feature space
      4. extend the language model to a dependency tree RNN to incorporate compositional semantics.
      5. between videos and sentences using a hsubject, verb, objecti compositional language model and a deep video model.
      6. This representation was then used for the task of cross-modal retrieval and video description. 
    - structured
      1. 作者任务结构化模型比相似性模型更优
      2. 部分排序、图片和语言的顺序嵌入
      3. CCA： CCA computes a linear projection which maximizes the correlation between two random variables (in our case modalities) and enforces orthogonality of the new space
      4. KCCA：
         - 非参数
         - 随着训练集规模扩大，扩展性变差
      5. DCCA：
         - 解决了扩展性
      6. CCA、KCCA、DCCA都是无监督
  - joint表征适用于所有模态都已经存在的情况（AVSR、情感、手势识别）coordinate表征使用测试时只有一种模态的情况

### translation

- Generative models are arguably more challenging to build as they require the ability to generate signals or sequences of symbols

- Example-Based
  - Retrieval
    1. Retrieval approaches in semantic space tend to perform better than their unimodal counterparts as they are retriev-ing examples in a more meaningful space that reflects both modalities and that is often optimized for retrieval
  - Combination
    1. 短语-->组合成描述
    2. 找到k个与源图像相似的image，然后组合他们的短语描述
    3. CNN预测短语-->a trigram constrained language model.生成描述
  - 问题：
    1. 模型是整个词典，large且推理缓慢（hash缓解）
    2. 单向翻译
  
- Generative

  1. both understand the source modality and to generate the target sequence or signal.
  2. much more difficult to evaluate
  3. Photo-realistic image generation has been less explored, and is still in early stages 

  - Grammar based
    1. The factor model exploits language statistics to deal with noisy visual representations
  - Encoder-decoder
    1. Most of the work on encoding words sentences uses distributional semantics [146] and variants of RNNs [13].
    2. it has been shown that using a coordinated space (see Section 3.2) leads to better results 
    3. Decoding is most often performed by an RNN or an LSTM using the encoded representation as the initial hidden state 
    4. This becomes especially difficult when generating long sequences as these models tend to forget the initial input. This has been partly addressed by including the encoded information during every step of the decoder [95].
    5. 使用transformer来generate images from sentences（对抗网络上有很大进展）
    6. 编码-解码模型可能知识在记忆训练数据而不是在学习如何理解视觉场景并生成它
  - Continuous（适用时间序列的translation）
    1. intended for sequence translation and produce outputs at every timestep in an online manner.
    2. 适合从序列到序列的translation
    3. 困难：时间一致性要求
    4.  cluster adaptive training
    5. 连续的编码器--解码器神经网络能有很好的效果

- 讨论

1. 多模态translation很难评估
2. 避免偏见（性别、年龄、文化）
3. 基于检索的评估指标



### alignment

- explicit（similarity metric.）

  - Unsupervised

    1.   Dynamic time warping (DTW)可以直接对其多模态，by手工的相似度度量
    2. While CCA based DTW models are able to find multimodal data alignment under a linear transformation, they are not able to model non-linear relationships.（无法处理非线性关系，但是deep canonical time wraping approach已经解决了这个困难，可以作为generalization of CCA and DTW）
    3. Various graphical models  for multimodal sequence alignment （require expert knowledge for construction）

  - Supervised

    - supervised sequence alignment techniques 
      take inspiration from unsupervised ones. 

    1. a method similar to canonical time warp-ing, but have also extended it to take advantage of existing (weak)supervisory alignment data for model training
    2. CCA to find a coordinated space between image regions and phrases for alignment
    3. trained a Gaussian mixture model and performed semi-supervised clustering together with an unsupervised latent variable graphical model to align speakers in an audio channel with their locations in a video
    4. trained a Markov random field to align objects in 3D scenes to nouns and pronouns in text descriptions.

    - Deep learning based approaches（due to very recent availability of aligned datasets in the lan-guage and vision communities）
      1. training a CNN to measure similarities between scenes and text. 
      2.  used an LSTM language model and a CNN visual one to evaluate the quality of a match between a referring expression and an object in an image（ extended this model to include relative appearance and context information that allows to better disambiguate between objects of the same type）
      3.  used an LSTM based scoring function to find similarities between image regions and their descriptions.

- implicit（ implicit alignment is used as an intermediate (often latent) step for another task）

  - Graphical models
    1.  Constructing such models requires training data or human expertise to define them manually. 
  - Neural networks
    1. 将alignment作为中间步骤，可以改善翻译效果
    2. A very popular way to address this is through attention , which allows the decoder to focus on sub-components of the source instance
    3. 注意力模型应用于问题解答，使模型具有更好的解释性
    4. 跨模态检索，（将图像区域与句子片段的表征点积，生成相似度测量）

- 讨论困难

  1. 很少有数据集是显示的标注对齐
  2. 在模态间设计相似度度量是困难的
  3. 可能存在多种对齐，而且并非一种模态中的所有元素在另一种模态中都有对应关系
  4. 对着标注数据集出现，对模态间相似性的监督学习成为可能
  5. 无监督的数据联合对齐和翻译或融合学习技术也开始流行起来



### fusion

三大好处：

1. 获得观察同一现象的多种模式，可以进行更稳健的预测（AVSR）
2. 使用多种模式可能会让我们捕捉到互补信息--这些信息在单个模式中是看不到的
3. 当其中一种模式缺失时，多模式系统仍然可以运行，例如，当人不说话时，可以从视觉信号中识别情绪[52]

- 多模态融合的应用范围非常广泛，包括视听语音识别[170]、多模态情感识别[200]、医学图像分析[93]和多媒体事件检测[122]



- Model-agnostic
  - Early
    1. it can learn to exploit the correlation and interactions between low level features of each modality
  - Late
    1.  model each individual modality better, allowing for more flexibility
    2. 当一种或多种模态缺失时，这种方法更容易进行预测，甚至可以在没有并行数据的情况下进行训练
    3. 后期融合忽略了模态之间的低水平交互
  - Hybrid
    1. 它已成功用于多模态说话人识别 [234] 和多媒体事件检测 [122]
  
- Model-based
  - Kernel-based
  
    1. 这些研究的广泛适用性证明了此类方法在不同领域和不同模态中的优势
    2. MKL 的一个优势是损失函数是凸函数，允许使用标准优化软件包和全局最优解进行模型训练[73]
    3. MKL 的主要缺点之一是在测试期间依赖训练数据（支持向量），导致推理速度慢和内存占用大。
  
  - Graphical models
  
    1. CRF 模型通过结合图像描述的视觉和文本信息，被用于更好地分割图像[63]
    2. CRF 模型已扩展到使用隐藏条件随机场对潜在状态建模 [172]，并已应用于多模态会议分割 [180]
    3. 多媒体分类任务中展示了多模态隐藏条件随机场的优势。
    4. 图形模型的优势在于能够轻松利用数据的空间和时间结构，因此在时间建模任务（如 AVSR 和多模态情感识别）中特别受欢迎。它们还允许在模型中加入人类专家的知识，并经常产生可解释的模型
  
  - Neural networks
  
    1. LSTM 模型用于连续的多模态情感识别，证明了它比图形模型和 SVM 更具优势
  
    2.  multi-view LSTM 
  
    3. 优势：
  
       - 深度神经网络方法在数据融合方面的一大优势是从大量数据中学习的能力
  
       - 最新的神经架构允许对多模态表征组件和融合组件进行端到端训练。
  
       - 能够学习其他方法难以学习的复杂决策边界。
  
    4. 劣势：
  
       - 神经网络方法的主要缺点是缺乏可解释性
  
  - 讨论
  
    - 挑战：
      1. 信号在时间上可能不一致（可能是密集的连续信号和稀疏的事件）
      2. 很难建立利用补充信息而不仅仅是互补信息的模型
      3. 每种模态在不同的时间点可能表现出不同类型和不同程度的噪声。



### co-learning

- 通过利用另一种（资源丰富的）模态的知识来帮助一种（资源贫乏的）模态建模。当其中一种模态资源有限--缺乏注释数据、输入噪声大、标签不可靠--时，这一点尤为重要
- Parallel
  - Co-training
    1. 基本算法是在每种模态中建立弱分类器，为未标注数据的标签相互引导
    2. 协同训练已被用于统计解析[185]、建立更好的视觉检测器[125]和视听语音识别[42]
    3. 通过过滤掉不可靠的样本[43]，它还被扩展用于处理模态之间的分歧
    4. （缺点）虽然协同训练是生成更多标注数据的有效方法，但它也可能导致训练样本有偏差，从而造成过度拟合
  - Transfer learning 
    1. Moon 等人[148]展示了如何将语音识别神经网络（基于音频）中的信息转移到唇读神经网络（基于图像）中，从而获得更好的可视化表示，并建立一个在测试期间无需音频信息即可用于唇读的模型
    2. Arora 和 Livescu [10] 利用声学和发音（嘴唇、舌头和下巴的位置）数据上的 CCA 建立了更好的声学特征。他们在构建 CCA 时仅使用发音数据，而在测试时仅使用由此产生的声学（单模态）表示。
- Non-parallel
  - Transfer learning
    1. Frome 等人[64]通过协调 CNN 视觉特征和在不同大型数据集上训练的 word2vec 文本特征[146]，利用文本改进了图像分类的视觉表征。以这种方式训练的视觉表征会产生更有意义的错误--将物体误认为是相似类别的物体[64]
    2. Mahasseni 和 Todorovic [134] 证明了如何使用基于三维骨架数据训练的自动编码器 LSTM，通过强制其隐藏状态之间的相似性来正则化基于彩色视频的 LSTM。
  - Concept grounding
    1. 概念基础是提高多项任务性能的有效方法。这也表明，语言和视觉（或音频）是互补的信息来源，将它们结合到多模态模型中往往能提高性能
    2. 接地并不总是能带来更好的性能[106], [107]，只有当接地与任务相关时才有意义--例如使用图像对视觉相关概念进行接地。
  - Zero shot learning
    - unimodal
      1. 单模态 ZSL 观察对象的组成部分或属性，例如通过音素来识别未听过的单词，或通过颜色、大小和形状等视觉属性来预测未见过的视觉类别 [57]。
    - multi-modal
      1. 多模态 ZSL 可借助曾见过物体的次模态来识别主模态中的物体。
      2. 多模态版本的 ZSL 面临着非平行数据的问题，因为不同模态之间所见类别的重叠是不同的。
- Hybrid data
  - Bridging
- 讨论



### 总结

- 多模态机器学习的一个具体领域似乎研究不足，那就是协同学习，即一种模态的知识有助于另一种模态的建模。这一挑战与协调表征的概念有关，在协调表征中，每种模式都保留自己的表征，但要找到一种方法来交换和协调知识。我们认为这些研究方向是未来研究的希望所在。



### idea

- 能否利用DBMs对于数据缺失的生成性优势弥补深度神经网络对于数据缺失的劣势？



### 问题

- 什么是dependency tree RNN

- 什么是fator模型

- 什么是条件随机场



# Multimodal Fusion on Low-quality Data: A Comprehensive Survey

方向：

1. 受异质噪声污染的高噪声多模态数据
2. 某些模态缺失的不完整多模态数据
3. 不平衡的多模态数据，即不同模态的质量或属性存在显著差异，
4. 质量变化的多模态数据，即每种模态的质量随着时间的推移而动态变化。



### introduction

1. 广泛使用的人工智能模型经常会被低质量数据中的虚假相关性和偏差所误导
2. 在现实世界中，不同模态的质量通常会因意外的环境因素或传感器问题而有所不同
3. imbalanced [7], [8], [9], [10], noisy [11] or even corrupted [12] multimodal data. 
4. 多模态融合在低质量数据下的4个核心挑战：
   - Noisy multimodal data
     - 学习如何减轻多模态数据中任意噪声的潜在影响
   - Incomplete multimodal data
     - 利用不完整的多模态数据进行学习
   - Imbalanced multimodal data.
     - 如何减轻偏差和模态间差异的影响
   - Quality dynamically varying multimodal data
     - 如何调整多模态数据的质量动态变化的多模态数据

### learning on noisy multimodal data

? 什么是更高层次的语义空间 ？

多模态噪声根据其来源可大致分为两类：

-  modal-specific noise
-  cross-modal noise

#### Modal-specific noise reduction（针对特征噪声）

- Modal-specific noise reduction methods很大程度上取决于输入模态和手头的任务

- 大多数针对特定模态的降噪方法focus on 从多模态数据中汇总有用的信息，并减轻噪声在多模态融合中的影响

1. Weighted average fusion

   - 一种简单的多模态降噪方法是对多模态数据进行对多模态数据进行平均融合：把图像分为高频和低频，对低频采用平均融合规则，对高频采用 guided filtering 

     [19] 

     > B. Rajalingam, F. Al-Turjman, R. Santhoshkumar, and M. Rajesh, “Intelligent multimodal medical image fusion with deep guided filtering,” Multimedia Systems, vol. 28, no. 4, pp. 1449–1463, 2022.

   - 由于the noise severity of each modality is different and varies among multimodal samples：使用加权平均

     [20]引导滤波  

     [21]计算不同带宽和级别的输入图像的小波变换模量最大值，旨在有效结合不同图像  
     
     [22]使用不同分数低阶矩  [23]将图像分为普通分量和创新分量，使用普通稀疏系数和创新稀疏系数表示源图像  [24]使用a gate mech-anism动态融合视觉特征来减轻语音信号中的噪声（假设视觉数据是干净的）  
     
     [25]使用具有马尔可夫依赖性的潜序列变量来决定视觉特征是否有利于视听语音增强  
     
     [18]使用transformer的软关联机制   
     
     [16]软注意力+硬注意力，融合块用于汇总来自立体相机的补充信息并生成两个差异图，通过比较差异图和激光雷达点，过滤掉原始数据中的噪声点  
     
     > S. Budhiraja et al., “Multimodal medical image fusion using modified fusion rules and guided filter,” in International Conference on Computing, Communication & Automation. IEEE, 2015, pp. 1067–1072.

2. Joint variation based fusion

   通常用于融合多种视觉模态，使用基于变化的降噪

   [26]使用一个像素域和小波域的a variational model，用于多焦点噪声图像的联合融合和去噪

   [27]采用the total variational model来融合使用多个传感器获取的图像  

   [28]constructing a fused image using the total variation model

   [29]该方法利用the total variation model对两种模式进行融合，从而提高了图像质量和信息整合能力。

   [30]relative total variation structure analysis (RTVSA) for urban area classification

   [31]为红外和可见光图像融合设计了一个两阶段增强（TSE）框架。他们的框架结合了注意力机制和特征链接模型（FLM），combining structure adaptive total-variational (SATV) and L1 sparsity terms

#### Cross-modal noise reduction（针对语义噪声）

- 许多多模态任务高度依赖于相关的对齐的多模态训练数据，然而，现实世界中的多模态对往往包含弱对齐甚至未对齐的样本

- 与特定模态噪声相比，跨模态模态噪声处于更高层次的语义空间

1.  rules-based filtering
   - [35]  CAT (Complexity, Action, and Text-spotting) is a filtering strategy，旨在选择有信息量的图像-文本对，从而减少跨模态噪声的影响
   - [37]  [38]  
   - 在多光谱物体检测中，图像配准（即空间配准）是一种常用的预处理方法。通过使用几何规则对齐两幅图像，就能在不同模态下纠正偏移的位置。
2. model-based rectifying
   - [12] Noisy Correspondence Rectifier (NCR) 
3. noise robustness regularization
   - [41] NLIP采用了噪声自适应正则化来避免噪声图像-文本对的过度拟合，并根据估计的噪声概率调整对齐标签
   - [42] OSCAR that detects object tags in images and uses them as anchor points for alignment
   - [43] multimodal contrastive learning

#### Discussion

- 这些方法通常侧重于特定场景，如多模态图像融合或自动驾驶，对一般噪声模式和学习范式的探索相对较少

研究课题：

1. First, it is important to leverage the correlation between noises in different modalities（利用不同模态噪声之间的相关性非常重要），例如，高光谱图像中波长相似的图像通常会表现出相似的噪声模式。
2. Second, it will be effective to leverage the complementarity between noisy and clean modalities for noise reduction（利用噪声模式和干净模式之间的互补性进行降噪也很有效）
3. Third, addressing high-level semantic noise poses an interesting direction and it is more challenging（处理高级语义噪声是一个有趣的方向，也更具挑战性），例如，如何利用多模态大语言模型（MLLM）来解决这一问题？



### INCOMPLETE MULTIMODAL LEARNING（不完整的多模态学习）

#### Imputation based incomplete multimodal learning

1. Model-agnostic imputation
   - [53]  我们提出了一种加权矩阵因式分解模型，为估算的模态分配较小的权重，以减轻对优化的负面影响
   - [55]  针对在线多模态聚类情况，还设计了一种动态权重和归因机制
   - [56]  利用从有效模态计算出的相似性值来估算图中缺失的元素
   - [57]  不完整内核中的缺失元素是通过所有列的平均值预先估算出来的
   - [58]  平均值，然后在图构建阶段为这些值赋一个小的权重
2. Learning based imputation
   1. Kernel/graph-based imputation
      - [59] 提出了一种基于高斯混合模型的方法，可以分析计算与缺失实例相关的缺失高斯核元素
      - [60] 提出了一种基于核化典型相关分析（KCCA）该方法通过最小化拉普拉斯核正则化来获得缺失的核元素（只适用与具有一个完整模态的双模态数据）
      - [48] collective kernel learning (CKL) 以相互补全与两个不完整模态相关的两个不完整内核
      - [61] 提出了一种基于稀疏重建技术的多模态内核补全方法，在内核内保存和内核间利用的框架下，联合完成所有内核的缺失行和列
      - [62] SLIM
      - [63]\[64]\[65]\[66] 提出了几种灵活的内核方法来恢复不完整多模态聚类任务中缺失的内核元素
      - 通过将所有不完整的内核对齐到一个共识内核上，这些方法就可以共同获得与缺失实例相关的缺失元素，以及所有模态共享的共识分区表示，对于不完整的多模态数据聚类
      - [67] 自适应图完成方法，用于恢复所有模态的所有图的缺失相似性，该方法主要采用基于稀疏表示的数据重建技术，借用其他模态的图信息来恢复各模态缺失的元素
   2. Raw data imputation
      - [68] VIGAN是基于生成式对抗网络（GAN）和自动编码器进行缺失模态恢复的一项开创性工作，VIGAN 利用 GAN 根据同一样本的另一种模态对缺失模态进行初始化，然后使用去噪自动编码器来完善恢复的缺失模态。VIGAN 的局限性在于它不适用于两种以上模态的数据
      - [69] [70] PMVC CGAN 和 AIMC 试图从未损坏模态编码的共同represetation中学习缺失模态
      - [72] CRA (cascaded residual autoencoder) 将所有模态堆叠为一个模态，通过优化单模态级联残差自动编码器网络，将缺失模态估算视为常规缺失特征补全
      - [73] RecFormer 采用了具有自注意结构的两级自动编码器网络，同步提取高级语义表征并恢复缺失数据
      - [74] 用相应语义邻域的平均值来 impute 模态
      - [75] 建立了一个双预测模型，该模型可以根据语义邻域来预测缺失模态的潜在 representation，然后使用解码器根据所观察到的模态的潜在表示来获得恢复的缺失模态
      - [76]\[77] 提供了两种基于矩阵因式分解的缺失模态估算方法，可以从通用 representation 反向重建缺失模态的数据
      - [78]  low-rank representation and tensor learning are introduced for joint missing modality recovery and graph
        completion
      - [79] 提出了不确定性诱导的不完整多视图数据分类（UIMC）模型（明确地考虑到了估算的可靠性）
      - [80] 将表征学习和数据恢复整合到一个统一的信息理论框架，称为 COMPLETER，COMPLETER 提出通过最大化相互信息来学习模态内一致性，并通过最小化条件熵来学习模态归约
      - [81] 提出了一种深度高斯过程模型，用于计算缺失的模态，进一步提高下游任务的性能
      - [82] 受对比学习的启发，Yang 等人提出了一种多模态估算范式，称为 SURE，用于稳健的多模态估算。该方法将完整的多模态配对视为正值，将随机取样的非配对样本视为负值
      - [83] 提出了一种基于原型的多模态估算方法, which incorporates a two-stream model with dual attention layers and contrastive learning mechanism to learn modal-specific prototypes and model the cross-modal relationship
      - [84] 提出了一种新颖的联合多视角聚类方法，利用无监督技术来评估和改进估算质量，有效地处理不完整多视图数据的各种情况

#### Imputation-free incomplete multimodal learning

1. Latent representation and projection learning
   - 一般是通过探索这些可用模态之间的部分对齐信息来获得多模态潜在表征
   - [85] partial multimodal clustering (PMVC) 基于矩阵因式分解
   - [86] 部分多模态子空间聚类进一步引入了图约束来捕捉潜在公共子空间中的结构信息
   - [87] 将潜在表征学习与回归整合到一个统一的框架中，用于基于不完整的多模态神经影像和基因数据的阿尔茨海默病诊断
   - doubly aligned incomplete multimodal clustering [88], one-pass incomplete multimodal clustering [89], and localized sparse incomplete multimodal clustering [90] are representative methods，为了解决只适用双模态数据的情况，引入加权矩阵因式分解法。这些模型一般将缺失实例的位置信息作为二进制值的加权矩阵强加给矩阵因式分解模型，以消除损失，同时减少缺失实例的负面影响。
   - [91] 用部分对齐学习项从不连贯的特定模态表征中学习一个完整的共同表征
   - [92] 为了防止模型过度关注某些维度较大的模态，投射式不完全多模态聚类将矩阵因式分解转化为加权投射学习模型的变体以从不完整的多模态数据中获得一致的表示
   - [93] 对于不完整多模态和不完整多标签分类任务，一种变体的加权投影学习模型被提出以发掘可用模态的信息
   - In summary, the above methods focus on exploring the available information of the observed modalities by introducing some techniques like the weighting mechanism to eliminate the loss of those missing modalities.
2. Graph learning based
   - 这种技术也被广泛考虑并融入到其他方法中，如基于矩阵因式分解的方法和基于深度学习的方法，以探索数据的结构信息，从而提高性能
   - [95] 提出了一个统一框架，该框架整合了基于自适应协作表示的模式特定图学习和共同规则化共识表征学习
3. Kernel learning based
   - Kernel learning based methods transform the learning phase from the raw-feature space into the kernel space
   - 对于不完整的多模态数据，所构建的与不同模态相关的内核也是不完整的，会有缺失的行和列。对于不完整多模态数据，核学习方法的目标是探索这些不完整内核的信息
   - [100] Late fusion incomplete multimodal clustering
   - [101] an efficient and effective regularized incomplete multimodal clustering method (EERIMVC)，which integrates the initialized consensus representation as prior knowledge. 
   - [102] Compared with EERIMVC, this method replaces the consensus representation with a clustering label matrix and an orthogonal matrix.
4. Deep learning based
   - [103] 提出了一种深度局部多模态聚类网络。该网络首先使用深度编码器提取多模态数据的潜在特征，然后采用图正则化部分多模态聚类模型来学习不完整双模态数据的共识表示
   - For data with more than two modalities, Wen et al. [104] proposed several deep incomplete multimodal clustering networks based on deep autoencoder framework, cognitive learning [105], and graph neural network [106], respectively
   - [107] 利用基于自动编码器的框架和多模态对比约束，开发了一种不完整的多模态多标签分类网络。
   - [108] （无估算、无融合深度网络）该方法挖掘了多模态聚类子空间中的互补性，并将这些互补信息转化为监督信息来指导网络训练
   - [109] 对于有监督的学习任务，交叉部分多模态网络，它可以灵活地学习任意缺失数据的共同表示，并保留共同信息和互补信息。
   - [110] 对于难度更大的不完整标签任务，有人提出了一种深度双不完整多模态多标签学习网络。该深度网络主要针对缺失的视图位置和缺失的标签位置引入了两个掩码约束，以减少对缺失视图位置和缺失标签位置的负面影响。

#### Discussion

研究课题：

- 针对缺失模态的估算实例的质量评估通常被忽视
- 用先验缺失信息来掩盖未知模态本身就难以弥合信息差距和信息模式缺失造成的信息不平衡问题。



### BALANCED MULTIMODAL LEARNING（均衡的多模态学习）

- 这种差异赋予了每种模态不同的属性，如收敛速度，从而使所有模态难以同时得到很好的处理和学习，给联合多模态学习带来了困难
- 尽管所有模态都描述了相同的概念，但它们与目标事件或对象相关的信息量却各不相同

#### Property-discrepancy method

- 多模态数据在来源和形式上的差异导致每种模式都有自己的学习特性

1. Learning-objective-based method
   - 基于学习目标的方法增加了单模态损失，使有针对性地调整单模态损失成为可能
2. Optimization-based method
   - 注重反向传播阶段
   - [114] 通过动态平衡各种模态的学习率来控制单模态参数更新。提出了平衡不同模式的优化方法。
     通过为更接近收敛的模式分配较低的学习率。
3. Architecture-based method
   - [116] 利用中心连接将视频流和音频流中的低级特征联系起来，捕捉空间（视频帧）和时间（音频帧）特征，从而实现高级语义表征并改进多模态联合学习

#### Quality-discrepancy methods

- [10] 对于联合训练的多模态后期融合框架，编码器网络只能学习模态的子集，其他模态可能无法被很好地发现

1. Learning-objective-based method 
   - 这些方法倾向于利用附加损失来打破多模态模型的模态偏好
   - [117] 赋予多模态对比学习损失，以限制音频和视频模态在语义空间中尽可能接近，然后帮助充分利用所有模态
   - [131] 出了一种新颖的正则化技术--多模态校准学习（Calibrating Multimodal Learning），以加强预测信度与模态数量之间的一致性，避免多模态分类模型过度依赖特定模态的问题
   - [118] 提出将预先训练的单模态特征提炼为多模态后期融合模型的相应部分，以避免学习者偏好一种模态
   - [119] 设计了一种自提炼训练策略，可以自动从优化较好的模态教导优化较差的模态
   - [120] 提出了多模态余弦损耗（MMCosine），该损耗会对特征和权重进行模态的 L2 归一化，以实现平衡的和更好的多模态细粒度学习。
   - [121] 引入了基于边际的正则化来确保多模态鲁棒性
2. Optimization-based method
   - 这些方法分别关注单模态梯度的大小和方向，以改善质量较低模态的学习
   - [8] 提出了一种即时梯度调节策略，在训练过程中动态监测各种模态对最终预测的贡献差异，并减弱主导模态的梯度幅度，从而更多地将注意力放在其他模态上。
   - [123] 其扩展到了基于图的预测模型中，自适应地调整梯度幅度，以减轻对高质量模态的偏好
   - [124] 将梯度幅度调制的想法扩展到了视听视频解析任务中，提出了一个模态分离的决策单元，以更好的评估在有更多模态间影响、更复杂的视听解析框架下的单一模态预测。
   - [122] 利用原型（即每个类别在表征空间中的中心点）来完善更新方向，从而提高单模态性能
3. Architecture-based method
   - 基于架构的方法旨在通过设计更好的单模态表征学习模块来平衡模态训练与质量差异
   - [125] 设计了一个多模态时态注意模块，该模块考虑了所有模态对每个单模态分支的时间影响，该模块促进了单模态分支之间的互动，并实现自适应模态间平衡
   - [126] 利用名为 "协调知识挖掘 "的协调特征空间来改进未充分优化的模态，在偏好的高质量模态的指导下
   - [127] 提出了变异特征融合模块，将融合特征视为随机变量，从而为不同类别和模态获得更均衡的分割性能
4. Data-augmentation-based method
   - 数据输入阶段增强低质量模态
   - [9] 首先测量了模型从一种模态学习的相对速度。与其他模态相比的相对学习速度、然后引入再平衡步骤，有意识地更新未充分利用的单模态分支，以加快模型从一种模态学习的速度。
   - [128] 建议自适应地屏蔽已学模式的数据输入，相应地鼓励模型更好地适应其他模态
   - [129] 引入了基于 Shapley 的样本级模态估值指标，以观察每种模态在每个样本预测过程中的贡献。然后在训练过程中动态地重新采样低贡献模态。这种方法实现了细粒度的多模态合作。

#### Discussion

研究课题：

- it is promising to explore the cooperation between modalities with theoretical guidance
- 此外，目前的方法主要局限于典型的多模态任务，主要是判别性任务和少数生成性任务。事实上，多模态大语言模型还需要联合整合不同的模态，因此也可能存在这种不平衡问题。我们期待在多模态大语言模型集中扩展当前的研究或设计新的解决方案。



### DYNAMIC MULTIMODAL FUSION（动态多模态融合）

> - 目前的多模态融合方法通常依赖于假设多模态数据的质量是静态的，而这在现实世界中并不总是成立的
>
> - 动态多模态融合旨在适应动态变化的多模态数据质量，并有选择性地整合多模态数据

#### Heuristic dynamic fusion

- [133] 在正常光照条件下，RGB 模式往往比热模式包含更多有用信息，但在弱光或夜间条件下，这种关系会发生逆转，热模式变得
  比 RGB 更可靠
- [132] 提出了一种光照感知加权机制，对每个输入场景的光照进行评估。这些光照权重被用来对子网络的输出进行动态整合，特别用于昼夜检测和分割
- [134] 提出了一种具有动态融合策略的编码器-解码器式网络。
- [112] 提出的信道交换网络（CEN）可根据由batich0-normalize层的缩放因子评估的信道重要性在模态子网络之间动态交换信息。通过在特定模态区域内执行信道交换和共享卷积滤波器，CEN 在单模态特征学习和多模态融合之间实现了平衡
- [135] AdaMML，这是一种自适应多模态学习，用于高效视频识别
- [137] 提出了 DynMM，它引入了模态级和融合级决策，允许自适应地选择输入模态和融合操作

#### Attention-based dynamic fusion

1. Self-attention
   - 自我注意通过允许每个元素与其他元素互动来模拟输入序列中的依赖性
   - [138] 提出了一种新颖的多模态交叉和自我关注网络 (MCSAN)，在语音情感分析中动态强调语言内容和声学信息。
   - [156] 设计了一种基于自我注意的多模态融合策略，以适应情感识别中文本和音频模态的不同质量。通过在特征层面对模态进行权衡，所提出的方法在面对噪声输入时具有额外的稳定性
2. Spatial attention
   - [140] MMTM 专为中间融合而设计，可插入到特征层次结构的不同级别，利用其他模态的知识重新校准低质量模态的信道特征
3. Channel attention
   - [139] 引入了一种新颖的轻量级融合模块，称为通道切换和空间注意（CSSA），用于多模态物体检测。CSSA 模块利用空间注意力有效地融合了来自不同模态的输入。使用最大值和平均值池化层增强空间注意力，从而在有效融合信息的同时保留独特的特征
4. Transformer
   - [141] Fusion Bottlenecks，这种新的转换器架构将跨模态交互限制在瓶颈标记和中后期融合层
   - [142] 利用具有共享参数的共享变换器架构来处理不同的视觉模态，包括图像、视频和单视角三维数据。其关键思路是通过采用自我注意机制来模拟跨模态的时间和空间关系
   - [143] 现有的 Transformer 变体可能会稀释多模态任务中的单模态注意力权重，从而导致整体性能不达标。为了克服这一问题，建议动态识别无信息的标记，并用来自其他模式的聚合特征取代它们
   - Yang 等人[?］提出利用注意力去完全处理测试时的损坏模态。设计了一种置信度的损失，以提高预测的可信度，减轻噪声的潜在影响

#### Uncertainty-aware dynamic fusion

1. Subjective Logic
   - 主观逻辑是分类任务中常用的一种不确定性估计方法，也是一种将 Dirichlet 分布参数与信念分布相关联的框架。
   - SL 提供了一个强大的工具，用于在不确定条件下进行推理并根据不完整或不确定的信息做出决策
   - [147] 提出了一种基于主观逻辑和证据理论的可信多模态分类（TMC）
   - 受 TMC 的启发，研究人员将基于 SL 的不确定性感知多模态融合应用于多种场景，包括医学图像分类 [149]、物体检测 [148]、[157]、语义分割 [2]
   - [158] 利用 Dirichlet 分布对多模态表征的不确定性进行建模，然后自适应地将分割和分类表征融合在一起
   - [150] 提出了一个改进的意见聚合框架，确保了不同意见之间的一致性，并实现了更可靠的预测
   - [159] TMC 的一个重要特点是 "在将另一种观点整合到原始观点之后，所获得的不确定性质量将减少"。他们提出了一种冲突性意见聚合策略
2. Entropy
   - [144] 提出了一种基于熵的多模态融合方法，命名为不确定性感知噪声或多模态融合（UNO）。具体来说，UNO 首先引入了几种不确定性测量方法，包括预测熵、互信息以及确定性熵。然后，它选择最保守（不确定性最高）的测量方法，并根据不确定性对每种模式的输出进行加权，从而将这些不确定性指标结合起来进行融合。最后，采用一种简单但有效的噪声或融合方案来融合来自多种模态的决策。在多模态语义分割任务中，UNO 可用于提高鲁棒性，以应对各种未知输入的退化。
3. Gaussian distributions
   - [151] 提出了动态不确定性感知网络（DUA-Net）。在无监督环境中整合噪声数据是一项具有挑战性的任务，传统的多模态方法要么将每种模态视为同等重要，要么将不同模态的权重调整为固定值，这些方法都无法捕捉多模态数据中的动态不确定性。从生成的角度，在不确定性的指导下，通过整合多种模式的内在信息，DUA-Net获得无噪声的表征。在不确定性估计的帮助下，DUA-Net 可以根据数据质量对单个样本的每种模态进行加权，从而充分利用高质量样本或模态，同时减少噪声样本或模态的影响。
   - [152] 对于视听情感识别提出了 Cali-brated and Ordinal Latent Distributions (COLD) 方法，为每种模态的不确定性建模。the variance of high-dimensional latent distributions is learned first for each modality as a measure of uncertainty
   - [146] 提出了一种概率集合技术（ProbEnsemble），合并多个检测器的预测，每个检测器使用不同的输入模式和架构。在这项工作中，作者采用具有单一方差的高斯形式来衡量单模态预测的不确定性。然后，他们按照贝叶斯算法对来自多种模态的输出进行概率融合。所提出的概率集合框架可以估算出每个检测建议的可能性，然后将它们结合起来得出更准确、更稳健的检测结果。
4. Normal-inverse Gamma distribution
   - [153] 提出了一种基于正态逆高斯（NIG）混合模型的新的多模态融合方法。这种 NIG 混合模型类似于决策级融合方法，它结合了多个 NIG 分布以输出每种模式的不确定性和总体不确定性。在这项工作中，NIG 分布被用来模拟特定模式的认识不确定性（EU）和时间不确定性（AU），每种模式对最终预测的贡献可根据其质量和不确定性进行动态调整。质量和不确定性，从而实现更可靠、更准确的预测。
5. Prediction confidence methods
   - 与不确定性估计算法不同，置信度校准方法旨在通过直接校准分类结果来获取置信度，而无需对未知数据分布进行建模
   - [160] 最大类概率（MCP）可被视为获得预测信度的基准方法。
   - [161] 虽然 MCP 在分类中很有效，但通常会导致置信度过高，尤其是在错误预测时。用真类概率 (TCP) 来获得更可靠的分类信度。
   - [154] 提出了一种名为 "多模态动态 "的多模态分类方法。该方法同时评估了特征级和模态级的信息量，从而以可信的方式有选择性地融合多种模态。具体来说，它使用稀疏门控策略和真实类概率估计来评估每个样本的特征和模态的不同重要性，从而实现更可靠的融合。
   - [33] 提出一种置信度感知融合方法，以选择性的整合来自RGB和热度图的特征 for 多光谱行人检测。该方法预测了每种模态的分类信度，然后执行特征再加权，以强调来自更可靠模态的线索，并根据置信度分数抑制不那么有用的线索。
6. Theoretical justification
   - [162] 从泛化能力的角度来看，多模态学习优于单模态学习
   - [145] 与传统的静态方法相比，不确定性感知的动态多模态学习能建立更严格的泛化误差约束。

#### Discussion

动态多模态学习方法关注的是模态质量随样本、时间或空间的变化而变化，这种变化广泛存在，但往往被忽视。

- 可以在 SOTA 多模态模型（如 CLIP）中考虑动态原则。
- 实际应用中有很多动态场景（如自动驾驶、医疗图像融合），因此设计针对特定应用的动态融合策略很有意义。

### CONCLUSION（总结）

- 用于基础模型的低质量多模态数据，如 CLIP。
- 用于融合以外的其他任务的低质量多模态数据，如alignment (retrieval)
- 噪音、不完整、不平衡和动态（如对抗性）之外的其他低质量形式。



# Attention Is All You Need（Transformer）

- Encoder and Decoder Stacks
- Attention
  - Scaled Dot-Product Attention
  - Multi-Head Attention
  - Applications of Attention in our Model



# BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding























































